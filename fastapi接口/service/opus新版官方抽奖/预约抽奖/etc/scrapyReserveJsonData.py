# -*- coding: utf-8 -*-
import asyncio
import os
import time
from dataclasses import dataclass
from functools import reduce
from typing import AsyncGenerator

import aiofiles
import pandas

import Bilibili_methods.all_methods
from fastapiæ¥å£.log.base_log import reserve_lot_logger
from fastapiæ¥å£.service.BaseCrawler.CrawlerType import UnlimitedCrawler, ParamsType
from fastapiæ¥å£.service.BaseCrawler.model.base import WorkerStatus
from fastapiæ¥å£.service.BaseCrawler.plugin.statusPlugin import StatsPlugin, SequentialNullStopPlugin
from fastapiæ¥å£.service.grpc_module.grpc.bapi.biliapi import reserve_relation_info
from fastapiæ¥å£.service.opusæ–°ç‰ˆå®˜æ–¹æŠ½å¥–.Model.BaseLotModel import BaseSuccCounter, ProgressCounter
from fastapiæ¥å£.service.opusæ–°ç‰ˆå®˜æ–¹æŠ½å¥–.é¢„çº¦æŠ½å¥–.db.models import TReserveRoundInfo, TUpReserveRelationInfo
from fastapiæ¥å£.service.opusæ–°ç‰ˆå®˜æ–¹æŠ½å¥–.é¢„çº¦æŠ½å¥–.db.sqlHelper import bili_reserve_sqlhelper
from fastapiæ¥å£.utils.Common import asyncio_gather
from utl.ä»£ç†.request_with_proxy import request_with_proxy

BAPI = Bilibili_methods.all_methods.methods()


class SuccCounter(BaseSuccCounter):
    first_reserve_id = 0
    latest_reserve_id: int = 0  # æœ€åçš„rid
    latest_succ_reserve_id: int = 0  # æœ€åè·å–æˆåŠŸçš„åŠ¨æ€id


@dataclass
class dynamic_timestamp_info:
    dynamic_timestamp: int = 0
    ids: int = 0

    def get_time_str_until_now(self):
        return self.seconds_to_hms(int(time.time()) - self.dynamic_timestamp)

    def seconds_to_hms(self, seconds):
        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        secs = seconds % 60
        return f"{hours:02d}å°æ—¶{minutes:02d}åˆ†{secs:02d}ç§’"


class ReserveScrapyRobot(UnlimitedCrawler[int]):
    async def on_run_end(self, end_param):
        """
            é€€å‡ºæ—¶å¿…å®šæ‰§è¡Œ
        """
        if os.path.exists(self.unknown):
            await self.file_remove_repeat_contents(self.unknown)
        if os.path.exists(self.getfail):
            await self.file_remove_repeat_contents(self.getfail)
        reserve_lot_logger.info(f'å…±{self.stats_plugin.processed_items_count}æ¬¡è·å–åŠ¨æ€'
                                f'å…¶ä¸­{self.stats_plugin.succ_count} ä¸ªæœ‰æ•ˆåŠ¨æ€')

    async def is_stop(self) -> bool:
        async with self.dynamic_ts_lock:
            if int(time.time()) - self.dynamic_timestamp.dynamic_timestamp <= self.EndTimeSeconds:  # å¦‚æœè¶…è¿‡äº†æœ€å¤§data
                if self.null_stop_plugin.sequential_null_count > 30:
                    return True
            else:
                reserve_lot_logger.debug(
                    f"æœ€è¿‘çš„é¢„çº¦æ—¶é—´é—´éš”è¿‡é•¿{self.dynamic_timestamp.get_time_str_until_now()}")
        return False

    async def key_params_gen(self, params: ParamsType) -> AsyncGenerator[ParamsType, None]:
        while 1:
            params += 1
            yield params

    async def handle_fetch(self, params: ParamsType) -> WorkerStatus:
        return await self.resolve_reserve(params)

    def __init__(self):
        self.sem_limit = 10
        self.stats_plugin = StatsPlugin(self)
        self.null_time_quit = 500  # é‡åˆ°è¿ç»­500æ¡dataä¸ºNoneçš„sid åˆ™é€€å‡º
        self.null_stop_plugin = SequentialNullStopPlugin(self, self.null_time_quit)
        super().__init__(
            plugins=[self.stats_plugin, self.null_stop_plugin],
            max_sem=self.sem_limit,
            _logger=reserve_lot_logger
        )
        self._use_custom_proxy = True
        self._is_use_available_proxy = False  # æ˜¯å¦å¥—ç”¨æ€¥éœ€å®Œæˆçš„apiçš„é‚£å¥—è®¾ç½®
        self.sqlHelper = bili_reserve_sqlhelper
        self.current_dir = os.path.dirname(os.path.abspath(__file__))
        self.now_round_id = 0
        self.ids_list = []
        self.ids_change_lock = asyncio.Lock()
        self.proxy_request = request_with_proxy()
        self.proxy_request.mode = 'rand'
        # {"proxy":{"http":1.1.1.1},"status":"å¯ç”¨|-412|å¤±æ•ˆ","update_ts":time.time(), }
        self.EndTimeSeconds = 3 * 3600  # æå‰å¤šä¹…é€€å‡ºçˆ¬åŠ¨æ€ ï¼ˆç°åœ¨ä¸åº”è¯¥æŒ‰ç…§è¿™ä¸ªä½œä¸ºé€€å‡ºçš„æ¡ä»¶ï¼Œå› ä¸ºé¢„çº¦ç°åœ¨æœ‰äº›æ˜¯ä¹±åºæ’åˆ—çš„ï¼Œæ‰€ä»¥åº”è¯¥ä»¥dataä¸ºNoneä½œä¸ºåˆ¤æ–­æ ‡å‡†ï¼‰
        self.rollback_num = 100  # è·å–å®Œä¹‹åçš„å›æ»šæ•°é‡
        self.dynamic_ts_lock = asyncio.Lock()
        self.highlight_word_list = ['jdå¡', 'äº¬ä¸œå¡', 'çº¢åŒ…', 'ä¸»æœº', 'æ˜¾å¡', 'ç”µè„‘', 'å¤©çŒ«å¡', 'çŒ«è¶…å¡', 'ç°é‡‘',
                                    'è§ç›˜', 'è€³æœº', 'é¼ æ ‡', 'æ‰‹åŠ', 'æ™¯å“', 'ps5', 'å†…å­˜', 'é£æ‰‡', 'æ•£çƒ­', 'æ°´å†·',
                                    'ä¸»æ¿', 'ç”µæº', 'æœºç®±', 'fgo'
            , 'æŠ˜ç°', 'æ¨±ç³', 'ç›ˆé€š', 'ğŸ§§', 'é”®ç›˜']  # éœ€è¦é‡ç‚¹æŸ¥çœ‹çš„å…³é”®è¯åˆ—è¡¨
        self.list_type_wrong = list()  # å‡ºé”™åŠ¨æ€å†…å®¹
        self.list_deleted_maybe = list()  # å¯èƒ½åŠ¨æ€å†…å®¹
        self.ids = int()
        self.dynamic_timestamp: dynamic_timestamp_info = dynamic_timestamp_info()
        self.getfail = None  # æ–‡ä»¶
        self.unknown = None  # æ–‡ä»¶
        # æ–‡ä»¶
        self.list_getfail = list()
        self.list_unknown = list()
        # å†…å®¹
        self.file_list_lock = asyncio.Lock()

        self.refresh_progress_counter: ProgressCounter | None = None

    def write_in_file(self):
        def my_write(path_Name, content_list: list, write_mode='a+'):
            with open(path_Name, mode=write_mode, encoding='utf-8') as f:
                f.writelines('\n'.join(str(i) for i in content_list))

            content_list.clear()

        if self.list_getfail:
            my_write(self.getfail, self.list_getfail)
        if self.list_unknown:
            my_write(self.unknown, self.list_unknown)

    async def resolve_reserve(self, sid: int, is_refresh=False) -> WorkerStatus:
        result = await self.resolve_reserve_by_sid(sid, is_refresh=is_refresh)
        if self.refresh_progress_counter and self.refresh_progress_counter.is_running:
            self.refresh_progress_counter.succ_count += 1
        return result

    async def resolve_reserve_by_sid(self, sid: int, is_refresh=False) -> WorkerStatus:
        '''
        è§£æåŠ¨æ€jsonï¼Œç„¶åä»¥dictå­˜åˆ°å¯¹åº”listé‡Œé¢
        :param is_refresh:
        :param sid:
        :return:
        '''
        is_force_api = False
        while 1:
            if not is_refresh:
                has_reserve_relation_ids = await self.sqlHelper.get_reserve_by_ids(sid)
            else:
                has_reserve_relation_ids = None
            if not is_force_api and has_reserve_relation_ids and has_reserve_relation_ids.code == 0 and has_reserve_relation_ids.sid is not None:
                req1_dict = has_reserve_relation_ids.raw_JSON
            else:
                req1_dict = await reserve_relation_info(
                    sid,
                    use_custom_proxy=self._use_custom_proxy,
                    is_use_available_proxy=self._is_use_available_proxy
                )
                req1_dict.update({'ids': sid})
                await self.sqlHelper.add_reserve_info_by_resp_dict(req1_dict, self.now_round_id)  # æ·»åŠ é¢„çº¦jsonåˆ°æ•°æ®åº“
            if is_refresh:
                return WorkerStatus.complete
            async with self.file_list_lock:
                dynamic_data_dict = req1_dict
                try:
                    dycode = req1_dict.get('code')
                except Exception as e:
                    dycode = 404
                    reserve_lot_logger.info(f'codeè·å–å¤±è´¥{req1_dict}')
                self.code_check(dycode)
                dymsg = req1_dict.get('msg')
                dymessage = req1_dict.get('message')
                dydata = req1_dict.get('data')
                if dydata is None:
                    return WorkerStatus.nullData
                if dycode == 404:
                    reserve_lot_logger.info(f'{dycode}\n {dymsg}\n {dymessage}')
                    self.list_getfail.append(dynamic_data_dict)
                    self.code_check(dycode)
                    return WorkerStatus.fail
                if dycode == 500207:  # {"code":500207,"msg":"","message":"","data":{}}#æ„Ÿè§‰åƒæ˜¯å½»åº•ä¸å­˜åœ¨çš„
                    self.list_deleted_maybe.append(dynamic_data_dict)
                    self.code_check(dycode)
                    return WorkerStatus.nullData
                if dycode == 500205:  # {"code":500205,"msg":"æ‰¾ä¸åˆ°åŠ¨æ€ä¿¡æ¯","message":"æ‰¾ä¸åˆ°åŠ¨æ€ä¿¡æ¯","data":{}}#æ„Ÿè§‰åƒæ˜¯æ²¡è¿‡å®¡æˆ–è€…åˆ æ‰äº†
                    self.list_deleted_maybe.append(dynamic_data_dict)
                    self.code_check(dycode)
                    return WorkerStatus.complete
                if dycode == 0:
                    try:
                        if str(sid) not in [str(x) for x in list(dydata.get('list', {}).keys())]:
                            reserve_lot_logger.critical(
                                f"\n\t\t\t\tç¬¬{str(self.stats_plugin.processed_items_count)}æ¬¡è·å–ç›´æ’­é¢„çº¦\t{time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}\t\t\t\trid:{sid}\nç›´æ’­é¢„çº¦[{sid}]è·å–å¤±è´¥ï¼Œå“åº”ä¸åŒ¹é…ï¼"
                                f"{req1_dict}")
                            is_force_api = True  # å¼ºåˆ¶ä½¿ç”¨apiè·å–æ•°æ®ï¼Œä¸ä¿¡ä»»æ•°æ®åº“å†…æ•°æ®äº†
                            continue
                        dynamic_timestamp = dynamic_data_dict.get('data').get('list').get(str(sid)).get('stime')
                        async with self.dynamic_ts_lock:
                            if sid > self.dynamic_timestamp.ids and dynamic_timestamp:
                                self.dynamic_timestamp.dynamic_timestamp = dynamic_timestamp
                                self.dynamic_timestamp.ids = sid
                        reserve_lot_logger.info(
                            f"\n\t\t\t\tç¬¬{str(self.stats_plugin.processed_items_count)}æ¬¡è·å–ç›´æ’­é¢„çº¦\t{time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}\t\t\t\trid:{sid}\nç›´æ’­é¢„çº¦[{sid}]è·å–æˆåŠŸï¼Œç›´æ’­é¢„çº¦åˆ›å»ºæ—¶é—´ï¼š{BAPI.timeshift(self.dynamic_timestamp.dynamic_timestamp)}")
                    except Exception as e:
                        reserve_lot_logger.exception(
                            f'{e}\n\t\t\t\tç¬¬{self.stats_plugin.processed_items_count}æ¬¡è·å–ç›´æ’­é¢„çº¦\t' + time.strftime(
                                '%Y-%m-%d %H:%M:%S',
                                time.localtime()) +
                            '\t\t\t\trid:{}'.format(sid) + '\n' +
                            f'ç›´æ’­é¢„çº¦å¤±æ•ˆï¼Œè¢«åˆ é™¤:{req1_dict}\nå½“å‰å·²ç»æœ‰{self.null_stop_plugin.sequential_null_count}æ¡dataä¸ºNoneçš„sid'
                        )
                    self.code_check(dycode)
                    return WorkerStatus.complete
                if dycode == -412:
                    self.code_check(dycode)
                    reserve_lot_logger.info(req1_dict)
                    self.list_getfail.append(dynamic_data_dict)
                    return WorkerStatus.fail
                if dycode != 0:
                    self.list_unknown.append(dynamic_data_dict)
                return WorkerStatus.fail

    def code_check(self, dycode):
        if dycode == 0:
            return 0
        if dycode == 404:
            reserve_lot_logger.critical(f'æœªçŸ¥ç±»å‹ä»£ç {dycode}')
            return 0
        if dycode == 500205:
            return 0
        else:
            reserve_lot_logger.critical(f'æœªçŸ¥ç±»å‹ä»£ç ï¼š{dycode}')
        if dycode == -412:
            return -412
        elif dycode != 'None' and dycode != 500207 and \
                dycode != 500205 and dycode != 404 and dycode != -412 and self.dynamic_timestamp.dynamic_timestamp != 'None':
            pass

    def remove_list_dict_duplicate(self, list_dict_data):
        """
        å¯¹listæ ¼å¼çš„dictè¿›è¡Œå»é‡

        """
        run_function = lambda x, y: x if y in x else x + [y]
        return reduce(run_function, [[], ] + list_dict_data)

    async def main(self):
        await self._init()
        now_round: TReserveRoundInfo = await self.sqlHelper.get_latest_reserve_round()
        round_start_ts = int(time.time()) if now_round.is_finished else now_round.round_start_ts
        self.now_round_id = now_round.round_id + 1 if now_round.is_finished else now_round.round_id
        none_num1 = 0
        totoal_count1 = 0
        totoal_count2 = 0
        for ids_index in range(len(self.ids_list)):
            none_num1 = self.null_stop_plugin.sequential_null_count
            async with self.ids_change_lock:
                self.ids = self.ids_list[ids_index]
            async with self.dynamic_ts_lock:
                self.dynamic_timestamp = dynamic_timestamp_info()
            await self.run(self.ids_list[ids_index])
            self.ids = self.stats_plugin.end_params  # åŠ ä¸Šè¿™ä¸ªæ‰æ˜¯æœ€ç»ˆçš„idsï¼Œå¦åˆ™idså¹¶ä¸ä¼šæ”¹å˜
            totoal_count1 = self.stats_plugin.succ_count
            self.ids_list[ids_index] = self.ids
            reserve_lot_logger.critical(
                f'{self.ids}å·²ç»è¾¾åˆ°{self.null_stop_plugin.sequential_null_count}/{self.null_time_quit}æ¡dataä¸ºnullä¿¡æ¯æˆ–è€…æœ€è¿‘é¢„çº¦æ—¶é—´åªå‰©'
                f'{self.dynamic_timestamp.get_time_str_until_now()}\n'
                f'æœ€ç»ˆæˆåŠŸçš„idsï¼šhttps://api.bilibili.com/x/activity/up/reserve/relation/info?ids={self.stats_plugin.end_success_params}\n'
                f'æœ€ç»ˆids: https://api.bilibili.com/x/activity/up/reserve/relation/info?ids={self.stats_plugin.end_params}\n'
            )
        none_num2 = self.null_stop_plugin.sequential_null_count
        totoal_count2 = self.stats_plugin.succ_count
        finnal_rid_list = [
            str(self.ids_list[0] - self.rollback_num - none_num1),
            str(self.ids_list[1] - self.rollback_num - none_num2)
        ]
        reserve_lot_logger.critical(
            f'{self.ids_list}å·²ç»è¾¾åˆ°{self.null_stop_plugin.sequential_null_count}/{self.null_time_quit}æ¡dataä¸ºnullä¿¡æ¯æˆ–è€…æœ€è¿‘é¢„çº¦æ—¶é—´åªå‰©'
            f'{self.dynamic_timestamp.get_time_str_until_now()}ç§’ï¼Œ'
            f'idsï¼š{self.dynamic_timestamp.ids}ï¼Œé€€å‡ºï¼'
            f'å½“å‰ridè®°å½•åˆ†åˆ«å›æ»š{self.rollback_num + none_num1}å’Œ{self.rollback_num + none_num2}æ¡'
            f'æœ€ç»ˆå†™å…¥æ–‡ä»¶ridè®°å½•ï¼š{finnal_rid_list}')

        with open(os.path.join(self.current_dir, 'idsstart'), 'w', encoding='utf-8') as ridstartfile:
            ridstartfile.write("\n".join(
                finnal_rid_list))
        self.write_in_file()
        latest_reserve_lots = await self.generate_update_reserve_lotterys_by_round_id(self.now_round_id)
        new_round_info = TReserveRoundInfo(
            round_id=self.now_round_id,
            is_finished=True,
            round_start_ts=round_start_ts,
            round_add_num=totoal_count1 + totoal_count2 - 1 - none_num1 - none_num2,
            round_lot_num=len(latest_reserve_lots),
        )
        await self.sqlHelper.add_reserve_round_info(new_round_info)

    async def generate_update_reserve_lotterys_by_round_id(self, round_id) -> list[TUpReserveRelationInfo]:
        """
        è·å–ç‰¹å®šroundæ›´æ–°çš„é¢„çº¦æŠ½å¥–å¹¶å†™å…¥æ–‡ä»¶ï¼Œå¦‚æœæœ¬æ¬¡roundæ›´æ–°çš„æŠ½å¥–æ•°é‡ä¸º0,åˆ™æŠ¥é”™é€€å‡ºï¼
        :return:
        """
        exclude_attrs = ['new_field', 'reserve_round', 'reserve_round_id',
                         'raw_JSON']
        latest_reserve_lottery = await self.sqlHelper.get_reserve_lotterys_by_round_id(round_id)
        newly_updated_reserve_list = self.sqlHelper.SqlAlchemyObjList2DictList(
            latest_reserve_lottery,
            TUpReserveRelationInfo,
            exclude_attrs
        )
        if not os.path.exists(os.path.join(self.current_dir, 'result')):
            os.mkdir(os.path.join(self.current_dir, 'result'))
        newly_updated_reserve_file_name = os.path.join(self.current_dir, 'result/æœ€åä¸€æ¬¡æ›´æ–°çš„ç›´æ’­é¢„çº¦æŠ½å¥–.csv')
        if len(newly_updated_reserve_list) == 0:
            reserve_lot_logger.error('æ›´æ–°æŠ½å¥–æ•°é‡ä¸º0ï¼Œæ£€æŸ¥ä»£ç ï¼')
        df = pandas.DataFrame(newly_updated_reserve_list)
        open(newly_updated_reserve_file_name, 'w').close()
        df.to_csv(newly_updated_reserve_file_name, header=True, encoding='utf-8', index=False, sep='\t')
        return newly_updated_reserve_list

    async def file_remove_repeat_contents(self, filename: str):
        s = set()
        l = []
        async with aiofiles.open(filename, "r", encoding="utf-8") as f:
            for line in await f.readlines():
                line = line.strip()
                if line not in s:
                    s.add(line)
                    l.append(line)
        if l:
            async with aiofiles.open(filename, "w", encoding="utf-8") as f:
                for line in l:
                    await f.write(line + "\n")

    async def refresh_not_drawn_lottery(self):
        self.refresh_progress_counter = ProgressCounter()
        all_not_drawn_reserve_lottery = await self.sqlHelper.get_all_undrawn_reserve_lottery()
        all_num = len(all_not_drawn_reserve_lottery)
        self.refresh_progress_counter.total_num = all_num
        running_num = 0
        reserve_lot_logger.debug(f'å¼€å§‹åˆ·æ–°æœªå¼€å¥–çš„é¢„çº¦å†…å®¹ï¼Œå…±è®¡{all_num}æ¡')
        task_list = []
        for reserve_lottery in all_not_drawn_reserve_lottery:
            task = asyncio.create_task(self.resolve_reserve(reserve_lottery.sid, is_refresh=True))
            task_list.append(task)
            running_num += 1
        await asyncio_gather(*task_list, log=self.log)
        self.refresh_progress_counter.is_running = False

    async def _init(self):
        '''
        åˆå§‹åŒ–ä¿¡æ¯
        :return:
        '''
        if not os.path.exists(os.path.join(self.current_dir, 'log')):
            os.mkdir(os.path.join(self.current_dir, 'log'))

        self.unknown = os.path.join(self.current_dir, 'log/æœªçŸ¥ç±»å‹.csv')

        self.getfail = os.path.join(self.current_dir, 'log/è·å–å¤±è´¥.csv')

        try:
            async with aiofiles.open(os.path.join(self.current_dir, 'idsstart'), 'r', encoding='utf-8') as ridstartfile:
                async with self.ids_change_lock:
                    self.ids_list.extend([int(x) for x in await ridstartfile.readlines()])
                    self.ids = self.ids_list[0]
            reserve_lot_logger.info('è·å–ridå¼€å§‹æ–‡ä»¶æˆåŠŸ\nidså¼€å§‹å€¼ï¼š{}'.format(self.ids))
            if self.ids <= 0:
                self.ids_list = [1750991, 4698648]
                reserve_lot_logger.info(f'è·å–ridå¼€å§‹æ–‡ä»¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼š{self.ids}')
        except Exception as e:
            reserve_lot_logger.exception('è·å–ridå¼€å§‹æ–‡ä»¶å¤±è´¥')
            raise e


if __name__ == "__main__":
    loop = asyncio.get_event_loop()
    rid_run = ReserveScrapyRobot()
    loop.run_until_complete(rid_run.main())
